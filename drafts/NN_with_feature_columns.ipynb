{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INTRUSION DETECTOR LEARNING\n",
    "Software to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders.  The intrusion detector learning task is to build a predictive model (i.e. a classifier) capable of distinguishing between bad connections, called intrusions or attacks, and good normal connections.\n",
    "\n",
    "The 1998 DARPA Intrusion Detection Evaluation Program was prepared and managed by MIT Lincoln Labs. The objective was to survey and evaluate research in intrusion detection.  A standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment, was provided.  The 1999 KDD intrusion detection contest uses a version of this dataset.\n",
    "\n",
    "Lincoln Labs set up an environment to acquire nine weeks of raw TCP dump data for a local-area network (LAN) simulating a typical U.S. Air Force LAN.  They operated the LAN as if it were a true Air Force environment, but peppered it with multiple attacks.\n",
    "\n",
    "The raw training data was about four gigabytes of compressed binary TCP dump data from seven weeks of network traffic.  This was processed into about five million connection records.  Similarly, the two weeks of test data yielded around two million connection records.\n",
    "\n",
    "A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol.  Each connection is labeled as either normal, or as an attack, with exactly one specific attack type.  Each connection record consists of about 100 bytes.\n",
    "\n",
    "Attacks fall into four main categories:\n",
    "\n",
    "- DOS: denial-of-service, e.g. syn flood;\n",
    "- R2L: unauthorized access from a remote machine, e.g. guessing password;\n",
    "- U2R:  unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;\n",
    "- probing: surveillance and other probing, e.g., port scanning.\n",
    "\n",
    "It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data.  This makes the task more realistic.  Some intrusion experts believe that most novel attacks are variants of known attacks and the \"signature\" of known attacks can be sufficient to catch novel variants.  The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only.\n",
    " \n",
    " \n",
    "#### DERIVED FEATURES\n",
    "Stolfo et al. defined higher-level features that help in distinguishing normal connections from attacks.  There are several categories of derived features.\n",
    "\n",
    "The ``same host'' features examine only the connections in the past two seconds that have the same destination host as the current connection, and calculate statistics related to protocol behavior, service, etc.\n",
    "\n",
    "The similar ``same service'' features examine only the connections in the past two seconds that have the same service as the current connection.\n",
    "\n",
    "\"Same host\" and \"same service\" features are together called  time-based traffic features of the connection records.\n",
    "\n",
    "Some probing attacks scan the hosts (or ports) using a much larger time interval than two seconds, for example once per minute.  Therefore, connection records were also sorted by destination host, and features were constructed using a window of 100 connections to the same host instead of a time window.  This yields a set of so-called host-based traffic features.\n",
    "\n",
    "Unlike most of the DOS and probing attacks, there appear to be no sequential patterns that are frequent in records of R2L and U2R attacks. This is because the DOS and probing attacks involve many connections to some host(s) in a very short period of time, but the R2L and U2R attacks are embedded in the data portions\n",
    "of packets, and normally involve only a single connection.\n",
    "\n",
    "Useful algorithms for mining the unstructured data portions of packets automatically are an open research question.  Stolfo et al. used domain knowledge to add features that look for suspicious behavior in the data portions, such as the number of failed login attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 'continuous',\n",
       " 'protocol_type': 'symbolic',\n",
       " 'service': 'symbolic',\n",
       " 'flag': 'symbolic',\n",
       " 'src_bytes': 'continuous',\n",
       " 'dst_bytes': 'continuous',\n",
       " 'land': 'symbolic',\n",
       " 'wrong_fragment': 'continuous',\n",
       " 'urgent': 'continuous',\n",
       " 'hot': 'continuous',\n",
       " 'num_failed_logins': 'continuous',\n",
       " 'logged_in': 'symbolic',\n",
       " 'num_compromised': 'continuous',\n",
       " 'root_shell': 'continuous',\n",
       " 'su_attempted': 'continuous',\n",
       " 'num_root': 'continuous',\n",
       " 'num_file_creations': 'continuous',\n",
       " 'num_shells': 'continuous',\n",
       " 'num_access_files': 'continuous',\n",
       " 'num_outbound_cmds': 'continuous',\n",
       " 'is_host_login': 'symbolic',\n",
       " 'is_guest_login': 'symbolic',\n",
       " 'count': 'continuous',\n",
       " 'srv_count': 'continuous',\n",
       " 'serror_rate': 'continuous',\n",
       " 'srv_serror_rate': 'continuous',\n",
       " 'rerror_rate': 'continuous',\n",
       " 'srv_rerror_rate': 'continuous',\n",
       " 'same_srv_rate': 'continuous',\n",
       " 'diff_srv_rate': 'continuous',\n",
       " 'srv_diff_host_rate': 'continuous',\n",
       " 'dst_host_count': 'continuous',\n",
       " 'dst_host_srv_count': 'continuous',\n",
       " 'dst_host_same_srv_rate': 'continuous',\n",
       " 'dst_host_diff_srv_rate': 'continuous',\n",
       " 'dst_host_same_src_port_rate': 'continuous',\n",
       " 'dst_host_srv_diff_host_rate': 'continuous',\n",
       " 'dst_host_serror_rate': 'continuous',\n",
       " 'dst_host_srv_serror_rate': 'continuous',\n",
       " 'dst_host_rerror_rate': 'continuous',\n",
       " 'dst_host_srv_rerror_rate': 'continuous'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_types, *features = requests.get('http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names').text.split('\\n')[:-1]\n",
    "attack_types = attack_types.split(',')\n",
    "attack_types[-1] = attack_types[-1][:-1]\n",
    "features_types_dict = {f.split(':')[0]: f.split(':')[1][1:-1] for f in features}\n",
    "features = list(features_types_dict.keys())\n",
    "features_types_dict['dst_host_srv_rerror_rate'] = 'continuous'\n",
    "features_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'back': 'dos',\n",
       " 'buffer_overflow': 'u2r',\n",
       " 'ftp_write': 'r2l',\n",
       " 'guess_passwd': 'r2l',\n",
       " 'imap': 'r2l',\n",
       " 'ipsweep': 'probe',\n",
       " 'land': 'dos',\n",
       " 'loadmodule': 'u2r',\n",
       " 'multihop': 'r2l',\n",
       " 'neptune': 'dos',\n",
       " 'nmap': 'probe',\n",
       " 'perl': 'u2r',\n",
       " 'phf': 'r2l',\n",
       " 'pod': 'dos',\n",
       " 'portsweep': 'probe',\n",
       " 'rootkit': 'u2r',\n",
       " 'satan': 'probe',\n",
       " 'smurf': 'dos',\n",
       " 'spy': 'r2l',\n",
       " 'teardrop': 'dos',\n",
       " 'warezclient': 'r2l',\n",
       " 'warezmaster': 'r2l',\n",
       " 'normal': 'normal'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf = requests.get('http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types').text\n",
    "buf = buf.split('\\n')[:-2]\n",
    "target_classes = {\n",
    "    'normal': 0,\n",
    "    'u2r': 1,\n",
    "    'r2l': 2,\n",
    "    'probe': 3,\n",
    "    'dos': 4\n",
    "}\n",
    "attack_types_dict = {line.split()[0]: line.split()[1] for line in buf}\n",
    "attack_types_dict['normal'] = 'normal'\n",
    "attack_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz'\n",
    "\n",
    "zip_file = tf.keras.utils.get_file(origin=_URL,\n",
    "                                   fname=\"kddcup.data.gz\")\n",
    "\n",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'kddcup.data')\n",
    "#df = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open(zip_file, 'rb') as f_in:\n",
    "    with open(base_dir, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class DFSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributes_names]#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "\n",
    "num_attrs = [0, 4, 5, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 22, 31, 32]\n",
    "cat_attrs = [1, 2, 3, 41]\n",
    "\n",
    "num_features_pipeline = Pipeline([\n",
    "    ('DataFrame2Numpy', DFSelector(attributes_names=num_attrs)),\n",
    "    ('Normalizer', MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_features_pipeline = Pipeline([\n",
    "    ('DataFrame2Numpy', DFSelector(attributes_names=cat_attrs)),\n",
    "    ('CategoricalEncoder', LabelBinarizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    data[num_attrs] = num_features_pipeline.fit_transform(data[num_attrs])\n",
    "    data[cat_attrs] = cat_features_pipeline.fit_transform(data[cat_attrs])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4898431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "lines_count = !wc -l {base_dir}\n",
    "lines_count = int(lines_count[0].split()[0])\n",
    "lines_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lines = tf.data.TextLineDataset(base_dir)\n",
    "#data_batches = data_lines.batch(128)\n",
    "\n",
    "#a = 1\n",
    "#for i in data_batches:a = np.frombuffer(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(a[0])[2:-2].split()\n",
    "#np.frombuffer(a)\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898426</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>2288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898427</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898428</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>218</td>\n",
       "      <td>3610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898429</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898430</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898431 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2   3    4      5   6   7   8   9   ...   32   33   34  \\\n",
       "0         0  tcp  http  SF  215  45076   0   0   0   0  ...    0  0.0  0.0   \n",
       "1         0  tcp  http  SF  162   4528   0   0   0   0  ...    1  1.0  0.0   \n",
       "2         0  tcp  http  SF  236   1228   0   0   0   0  ...    2  1.0  0.0   \n",
       "3         0  tcp  http  SF  233   2032   0   0   0   0  ...    3  1.0  0.0   \n",
       "4         0  tcp  http  SF  239    486   0   0   0   0  ...    4  1.0  0.0   \n",
       "...      ..  ...   ...  ..  ...    ...  ..  ..  ..  ..  ...  ...  ...  ...   \n",
       "4898426   0  tcp  http  SF  212   2288   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898427   0  tcp  http  SF  219    236   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898428   0  tcp  http  SF  218   3610   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898429   0  tcp  http  SF  219   1234   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898430   0  tcp  http  SF  219   1098   0   0   0   0  ...  255  1.0  0.0   \n",
       "\n",
       "           35    36   37    38   39   40      41  \n",
       "0        0.00  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "1        1.00  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "2        0.50  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "3        0.33  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "4        0.25  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "...       ...   ...  ...   ...  ...  ...     ...  \n",
       "4898426  0.33  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898427  0.25  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898428  0.20  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898429  0.17  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898430  0.14  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "\n",
       "[4898431 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(base_dir, header=None)\n",
    "df[41] = [i[:-1] for i in df[41].values]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icmp    2833545\n",
      "tcp     1870598\n",
      "udp      194288\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "ecr_i        2811660\n",
      "private      1100831\n",
      "http          623091\n",
      "smtp           96554\n",
      "other          72653\n",
      "              ...   \n",
      "tftp_u             3\n",
      "aol                2\n",
      "http_8001          2\n",
      "harvest            2\n",
      "http_2784          1\n",
      "Name: 2, Length: 70, dtype: int64\n",
      "\n",
      "SF        3744328\n",
      "S0         869829\n",
      "REJ        268874\n",
      "RSTR         8094\n",
      "RSTO         5344\n",
      "SH           1040\n",
      "S1            532\n",
      "S2            161\n",
      "RSTOS0        122\n",
      "OTH            57\n",
      "S3             50\n",
      "Name: 3, dtype: int64\n",
      "\n",
      "smurf              2807886\n",
      "neptune            1072017\n",
      "normal              972781\n",
      "satan                15892\n",
      "ipsweep              12481\n",
      "portsweep            10413\n",
      "nmap                  2316\n",
      "back                  2203\n",
      "warezclient           1020\n",
      "teardrop               979\n",
      "pod                    264\n",
      "guess_passwd            53\n",
      "buffer_overflow         30\n",
      "land                    21\n",
      "warezmaster             20\n",
      "imap                    12\n",
      "rootkit                 10\n",
      "loadmodule               9\n",
      "ftp_write                8\n",
      "multihop                 7\n",
      "phf                      4\n",
      "perl                     3\n",
      "spy                      2\n",
      "Name: 41, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in (1, 2, 3, 41):\n",
    "    print(df[i].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protocol_type</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_bytes</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898426</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>2288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898427</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898428</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>3610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898430</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898431 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   1   2   3    4      5   6   7   8   9   ...   32   33   34  \\\n",
       "duration        0   1   2   0  215  45076   0   0   0   0  ...    0  0.0  0.0   \n",
       "protocol_type   0   1   2   0  162   4528   0   0   0   0  ...    1  1.0  0.0   \n",
       "service         0   1   2   0  236   1228   0   0   0   0  ...    2  1.0  0.0   \n",
       "flag            0   1   2   0  233   2032   0   0   0   0  ...    3  1.0  0.0   \n",
       "src_bytes       0   1   2   0  239    486   0   0   0   0  ...    4  1.0  0.0   \n",
       "...            ..  ..  ..  ..  ...    ...  ..  ..  ..  ..  ...  ...  ...  ...   \n",
       "4898426         0   1   2   0  212   2288   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898427         0   1   2   0  219    236   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898428         0   1   2   0  218   3610   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898429         0   1   2   0  219   1234   0   0   0   0  ...  255  1.0  0.0   \n",
       "4898430         0   1   2   0  219   1098   0   0   0   0  ...  255  1.0  0.0   \n",
       "\n",
       "                 35    36   37    38   39   40      41  \n",
       "duration       0.00  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "protocol_type  1.00  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "service        0.50  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "flag           0.33  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "src_bytes      0.25  0.00  0.0  0.00  0.0  0.0  normal  \n",
       "...             ...   ...  ...   ...  ...  ...     ...  \n",
       "4898426        0.33  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898427        0.25  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898428        0.20  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898429        0.17  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "4898430        0.14  0.05  0.0  0.01  0.0  0.0  normal  \n",
       "\n",
       "[4898431 rows x 42 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in (1, 2, 3):\n",
    "    classes_list = list(dict(df[i].value_counts()).keys())\n",
    "    classes = {c: i for i, c in enumerate(classes_list)}\n",
    "    df[i] = df[i].apply(lambda x: classes[x])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255    3363886\n",
       "1       117468\n",
       "2        70459\n",
       "3        58016\n",
       "4        55638\n",
       "        ...   \n",
       "199        610\n",
       "202        607\n",
       "207        547\n",
       "206        523\n",
       "0           33\n",
       "Name: 32, Length: 256, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[32].hist(figsize=(14, 16))\n",
    "df[32].value_counts()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smurf': 2807886,\n",
       " 'neptune': 1072017,\n",
       " 'normal': 972781,\n",
       " 'satan': 15892,\n",
       " 'ipsweep': 12481,\n",
       " 'portsweep': 10413,\n",
       " 'nmap': 2316,\n",
       " 'back': 2203,\n",
       " 'warezclient': 1020,\n",
       " 'teardrop': 979,\n",
       " 'pod': 264,\n",
       " 'guess_passwd': 53,\n",
       " 'buffer_overflow': 30,\n",
       " 'land': 21,\n",
       " 'warezmaster': 20,\n",
       " 'imap': 12,\n",
       " 'rootkit': 10,\n",
       " 'loadmodule': 9,\n",
       " 'ftp_write': 8,\n",
       " 'multihop': 7,\n",
       " 'phf': 4,\n",
       " 'perl': 3,\n",
       " 'spy': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pandas.plotting import scatter_matrix\n",
    "#attrs = [1, 4]\n",
    "#df.plot(kind='scatter', x=1, y=4, figsize=(14, 16))\n",
    "dict(df[41].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smurf           dos     2807886\n",
      "neptune         dos     1072017\n",
      "normal          normal  972781\n",
      "satan           probe   15892\n",
      "ipsweep         probe   12481\n",
      "portsweep       probe   10413\n",
      "nmap            probe   2316\n",
      "back            dos     2203\n",
      "warezclient     r2l     1020\n",
      "teardrop        dos     979\n",
      "pod             dos     264\n",
      "guess_passwd    r2l     53\n",
      "buffer_overflow u2r     30\n",
      "land            dos     21\n",
      "warezmaster     r2l     20\n",
      "imap            r2l     12\n",
      "rootkit         u2r     10\n",
      "loadmodule      u2r     9\n",
      "ftp_write       r2l     8\n",
      "multihop        r2l     7\n",
      "phf             r2l     4\n",
      "perl            u2r     3\n",
      "spy             r2l     2\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder()\n",
    "#for i in (1, 2, 3, 41):\n",
    "#    data_column = df.drop(i, axis=1).values\n",
    "#    df[i] = encoder.fit_transform(data_column.reshape(-1, 1))\n",
    "attacks_count = dict(df[41].value_counts())\n",
    "for attack in attacks_count:\n",
    "    print('%-16s%-7s %d' % (attack, attack_types_dict[attack], attacks_count[attack]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:  7000 \n",
      "test_df:   2000 \n",
      "val_df:    750\n"
     ]
    }
   ],
   "source": [
    "TRAIN_NUM = 700\n",
    "TEST_NUM = 200\n",
    "\n",
    "train_df = df[df[41]=='smurf'][:TRAIN_NUM]\n",
    "test_df = df[df[41]=='smurf'][TRAIN_NUM:TRAIN_NUM+TEST_NUM]\n",
    "val_df = df[df[41]=='smurf'][TRAIN_NUM+TEST_NUM:975]\n",
    "\n",
    "classes = ['neptune', 'normal', 'satan', 'ipsweep', 'portsweep', 'nmap', 'back', 'warezclient', 'teardrop']\n",
    "\n",
    "for _class in classes:\n",
    "    train_df = train_df.merge(df[df[41]==_class][:TRAIN_NUM], how='outer')\n",
    "    test_df = test_df.merge(df[df[41]==_class][TRAIN_NUM:TRAIN_NUM+TEST_NUM], how='outer')\n",
    "    val_df = val_df.merge(df[df[41]==_class][TRAIN_NUM+TEST_NUM:975], how='outer')\n",
    "print('train_df: ', len(train_df), '\\ntest_df:  ', len(test_df), '\\nval_df:   ', len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "buf_df = train_df.copy()\n",
    "target = buf_df.pop(41)\n",
    "rnd_clf.fit(buf_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "buf_df = test_df.copy()\n",
    "target = buf_df.pop(41)\n",
    "test_predicted = rnd_clf.predict(buf_df)\n",
    "accuracy_score(target, test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf_df = val_df.copy()\n",
    "target = buf_df.pop(41)\n",
    "test_predicted = rnd_clf.predict(buf_df)\n",
    "accuracy_score(target, test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration : 0.0023083602301803485\n",
      "protocol_type : 0.04858460434201142\n",
      "service : 0.06972742916760599\n",
      "flag : 0.05179318289736214\n",
      "src_bytes : 0.07556083595102023\n",
      "dst_bytes : 0.029773539265002053\n",
      "land : 0.0\n",
      "wrong_fragment : 0.04162184633318212\n",
      "urgent : 0.0\n",
      "hot : 0.013485079329562001\n",
      "num_failed_logins : 0.0\n",
      "logged_in : 0.037136990400287714\n",
      "num_compromised : 0.030049154258104057\n",
      "root_shell : 0.0\n",
      "su_attempted : 0.0\n",
      "num_root : 1.1805494245817778e-05\n",
      "num_file_creations : 1.3667558902037723e-05\n",
      "num_shells : 1.6907636804434287e-07\n",
      "num_access_files : 5.809270921455728e-09\n",
      "num_outbound_cmds : 0.0\n",
      "is_host_login : 0.0\n",
      "is_guest_login : 0.003260887706236265\n",
      "count : 0.043881687022225876\n",
      "srv_count : 0.05024974439571705\n",
      "serror_rate : 0.036312094140783714\n",
      "srv_serror_rate : 0.01057980454282523\n",
      "rerror_rate : 0.02922713087829269\n",
      "srv_rerror_rate : 0.005094577225117189\n",
      "same_srv_rate : 0.021024891160846257\n",
      "diff_srv_rate : 0.053157424667422855\n",
      "srv_diff_host_rate : 0.00024089948357675642\n",
      "dst_host_count : 0.03811394272064211\n",
      "dst_host_srv_count : 0.0312550596305774\n",
      "dst_host_same_srv_rate : 0.032904290859924946\n",
      "dst_host_diff_srv_rate : 0.04299411331217381\n",
      "dst_host_same_src_port_rate : 0.05820041736799098\n",
      "dst_host_srv_diff_host_rate : 0.01800044536004545\n",
      "dst_host_serror_rate : 0.04642897219148367\n",
      "dst_host_srv_serror_rate : 0.012316372789250383\n",
      "dst_host_rerror_rate : 0.0425127364754834\n",
      "dst_host_srv_rerror_rate : 0.024177837956279098\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for (feature, importance) in zip(features_types_dict, rnd_clf.feature_importances_):\n",
    "    print(feature, ':', importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.30836023e-03, 4.85846043e-02, 6.97274292e-02, 5.17931829e-02,\n",
       "       7.55608360e-02, 2.97735393e-02, 0.00000000e+00, 4.16218463e-02,\n",
       "       0.00000000e+00, 1.34850793e-02, 0.00000000e+00, 3.71369904e-02,\n",
       "       3.00491543e-02, 0.00000000e+00, 0.00000000e+00, 1.18054942e-05,\n",
       "       1.36675589e-05, 1.69076368e-07, 5.80927092e-09, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.26088771e-03, 4.38816870e-02, 5.02497444e-02,\n",
       "       3.63120941e-02, 1.05798045e-02, 2.92271309e-02, 5.09457723e-03,\n",
       "       2.10248912e-02, 5.31574247e-02, 2.40899484e-04, 3.81139427e-02,\n",
       "       3.12550596e-02, 3.29042909e-02, 4.29941133e-02, 5.82004174e-02,\n",
       "       1.80004454e-02, 4.64289722e-02, 1.23163728e-02, 4.25127365e-02,\n",
       "       2.41778380e-02])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  warezclient \n",
      "Predicted:  ['warezclient']\n"
     ]
    }
   ],
   "source": [
    "data = df[df[41]==classes[-2]][975:976]\n",
    "data.pop(41)\n",
    "print('Class: ', classes[-2], '\\nPredicted: ', rnd_clf.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, f in enumerate(features_types_dict):\n",
    "#    print('%02d. %010s %s' % (i, features_types_dict[f], f))\n",
    "#for i in range(42):\n",
    "#    max_ = df[i].max()\n",
    "#    print(i, ': ', max_)\n",
    "#for i in (0, 4, 5, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 22, 31, 32):\n",
    "#    max_ = df[i].max()\n",
    "#    df[i] = df[i].apply(lambda x: x / max_)\n",
    "#df[41] = df[41].apply(lambda x: target_classes[attack_types_dict[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10_percent_num = len(df) / 10\n",
    "\n",
    "#df = df.sample(frac=1)\n",
    "#test_df = df[:10_percent_num]\n",
    "#val_df = df[10_percent_num:10_percent_num * 2]\n",
    "#df = df[10_percent_num * 2:]\n",
    "\n",
    "def df_to_dataset(data, main_df, label_index=41, shuffle=True, batch_size=32):\n",
    "    df = data.copy()\n",
    "    for i in range(41):\n",
    "        if i in cat_attrs:\n",
    "            df[i], _ = df[i].factorize()\n",
    "        if i in num_attrs:\n",
    "            max_ = main_df[i].max()\n",
    "            df[i] = train_df[i].apply(lambda x: x / max_)\n",
    "\n",
    "    df[label_index] = df[label_index].apply(lambda x: target_classes[attack_types_dict[x]])\n",
    "    df[label_index], _ = df[label_index].factorize()\n",
    "        \n",
    "    labels = df.pop(label_index)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = df_to_dataset(train_df, main_df=df, batch_size=BATCH_SIZE)\n",
    "val_dataset = df_to_dataset(val_df, main_df=df, batch_size=BATCH_SIZE)\n",
    "test_dataset = df_to_dataset(test_df, main_df=df, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
      "A batch of targets: tf.Tensor([2 2 1 0 2 2 0 2 1 3 0 2 0 0 0 0 0 2 0 2 2 1 2 1 0 3 0 0 2 2 0 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in dataset.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of targets:', label_batch )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f303442f290>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target.value_counts()\n",
    "target.hist(figsize=(14, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import feature_column\n",
    "def demo(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': <tf.Tensor: id=525, shape=(32,), dtype=float64, numpy=\n",
       " array([5.14323921e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])>,\n",
       " 'protocol_type': <tf.Tensor: id=539, shape=(32,), dtype=int32, numpy=\n",
       " array([1, 1, 2, 1, 1, 2, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 2], dtype=int32)>,\n",
       " 'service': <tf.Tensor: id=544, shape=(32,), dtype=int32, numpy=\n",
       " array([ 1,  2,  2, 14,  4,  2,  2, 14,  0,  2,  0,  0,  2, 31,  4,  4,  2,\n",
       "        14,  4,  0,  0,  2, 23,  4, 22,  4,  4,  2,  2,  2,  0,  2],\n",
       "       dtype=int32)>,\n",
       " 'flag': <tf.Tensor: id=526, shape=(32,), dtype=int32, numpy=\n",
       " array([4, 5, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 5, 7, 2, 0, 0, 0, 2,\n",
       "        2, 0, 2, 0, 0, 2, 2, 1, 0, 0], dtype=int32)>,\n",
       " 'src_bytes': <tf.Tensor: id=545, shape=(32,), dtype=float64, numpy=\n",
       " array([0.00000000e+00, 0.00000000e+00, 2.02903860e-08, 0.00000000e+00,\n",
       "        1.78990191e-07, 2.02903860e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.47845657e-07, 2.02903860e-08, 7.47845657e-07, 7.47845657e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.95227734e-05, 3.13283560e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.95227734e-05, 7.47845657e-07,\n",
       "        7.47845657e-07, 0.00000000e+00, 0.00000000e+00, 3.95227734e-05,\n",
       "        0.00000000e+00, 3.95227734e-05, 3.95227734e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.47845657e-07, 2.02903860e-08])>,\n",
       " 'dst_bytes': <tf.Tensor: id=514, shape=(32,), dtype=float64, numpy=\n",
       " array([1.14509289e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.02814073e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.34686817e-06, 5.57278538e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.34686817e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.34686817e-06,\n",
       "        0.00000000e+00, 6.34686817e-06, 6.34686817e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])>,\n",
       " 'land': <tf.Tensor: id=530, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'wrong_fragment': <tf.Tensor: id=552, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])>,\n",
       " 'urgent': <tf.Tensor: id=551, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'hot': <tf.Tensor: id=527, shape=(32,), dtype=float64, numpy=\n",
       " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02597403,\n",
       "        0.01298701, 0.        , 0.        , 0.02597403, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02597403, 0.        ,\n",
       "        0.02597403, 0.02597403, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ])>,\n",
       " 'num_failed_logins': <tf.Tensor: id=534, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'logged_in': <tf.Tensor: id=531, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'num_compromised': <tf.Tensor: id=533, shape=(32,), dtype=float64, numpy=\n",
       " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00013371,\n",
       "        0.        , 0.        , 0.        , 0.00013371, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00013371, 0.        ,\n",
       "        0.00013371, 0.00013371, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ])>,\n",
       " 'root_shell': <tf.Tensor: id=541, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'su_attempted': <tf.Tensor: id=550, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'num_root': <tf.Tensor: id=537, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'num_file_creations': <tf.Tensor: id=535, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'num_shells': <tf.Tensor: id=538, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'num_access_files': <tf.Tensor: id=532, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       " 'num_outbound_cmds': <tf.Tensor: id=536, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'is_host_login': <tf.Tensor: id=529, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'is_guest_login': <tf.Tensor: id=528, shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'count': <tf.Tensor: id=512, shape=(32,), dtype=float64, numpy=\n",
       " array([0.00195695, 0.00195695, 0.18590998, 0.73189824, 0.02348337,\n",
       "        0.19178082, 0.11937378, 0.79843444, 1.        , 0.06457926,\n",
       "        1.        , 1.        , 0.00195695, 0.92367906, 0.00978474,\n",
       "        0.01174168, 0.00195695, 0.99608611, 0.00978474, 1.        ,\n",
       "        1.        , 0.00195695, 0.00195695, 0.00782779, 0.00195695,\n",
       "        0.00978474, 0.00978474, 0.21722114, 0.42465753, 0.1369863 ,\n",
       "        0.99608611, 0.06457926])>,\n",
       " 'srv_count': <tf.Tensor: id=546, shape=(32,), dtype=int32, numpy=\n",
       " array([  1,   1,  95,   1,  13,  96,   1,   1, 511,  33, 511, 511,   1,\n",
       "         17,   5,   7,   1,   1,   5, 511, 511,   1,   1,   4,   1,   5,\n",
       "          5,   1,   1,   7, 509,  33], dtype=int32)>,\n",
       " 'serror_rate': <tf.Tensor: id=543, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 0.06, 0.  , 0.01, 0.02, 0.07, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.07, 0.  , 0.  , 1.  , 0.08, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.06, 1.  , 0.  , 0.  ])>,\n",
       " 'srv_serror_rate': <tf.Tensor: id=549, shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])>,\n",
       " 'rerror_rate': <tf.Tensor: id=540, shape=(32,), dtype=float64, numpy=\n",
       " array([1.  , 1.  , 0.  , 0.91, 0.  , 0.01, 0.92, 0.9 , 0.  , 0.  , 0.  ,\n",
       "        0.  , 1.  , 0.9 , 0.2 , 0.33, 0.  , 0.91, 0.2 , 0.  , 0.  , 1.  ,\n",
       "        1.  , 0.  , 1.  , 0.2 , 0.  , 0.91, 0.88, 0.  , 0.  , 0.  ])>,\n",
       " 'srv_rerror_rate': <tf.Tensor: id=548, shape=(32,), dtype=float64, numpy=\n",
       " array([1.  , 1.  , 0.  , 1.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 1.  , 1.  , 0.2 , 0.43, 0.  , 1.  , 0.2 , 0.  , 0.  , 1.  ,\n",
       "        1.  , 0.  , 1.  , 0.2 , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  ])>,\n",
       " 'same_srv_rate': <tf.Tensor: id=542, shape=(32,), dtype=float64, numpy=\n",
       " array([1.  , 1.  , 1.  , 0.  , 1.  , 0.98, 0.02, 0.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 0.04, 1.  , 1.  , 1.  , 0.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 0.01, 0.  , 0.1 , 1.  , 1.  ])>,\n",
       " 'diff_srv_rate': <tf.Tensor: id=513, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 1.  , 0.  , 0.03, 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.96, 0.  , 0.  , 0.  , 0.95, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.07, 0.  , 0.  ])>,\n",
       " 'srv_diff_host_rate': <tf.Tensor: id=547, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])>,\n",
       " 'dst_host_count': <tf.Tensor: id=515, shape=(32,), dtype=float64, numpy=\n",
       " array([0.01568627, 1.        , 1.        , 1.        , 0.14901961,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.06666667, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.07843137, 0.65490196,\n",
       "        1.        , 0.19215686, 0.22745098, 1.        , 0.25490196,\n",
       "        0.59215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.73333333, 1.        ])>,\n",
       " 'dst_host_srv_count': <tf.Tensor: id=521, shape=(32,), dtype=float64, numpy=\n",
       " array([0.00392157, 0.00392157, 0.37254902, 0.00392157, 1.        ,\n",
       "        0.37647059, 0.00392157, 0.00392157, 1.        , 0.52156863,\n",
       "        0.87058824, 0.64705882, 0.00392157, 0.0627451 , 1.        ,\n",
       "        1.        , 0.00392157, 0.00392157, 0.07843137, 0.08627451,\n",
       "        1.        , 0.00392157, 0.00784314, 1.        , 0.00392157,\n",
       "        0.59215686, 1.        , 0.00392157, 0.00392157, 0.02745098,\n",
       "        0.16470588, 0.12941176])>,\n",
       " 'dst_host_same_srv_rate': <tf.Tensor: id=519, shape=(32,), dtype=float64, numpy=\n",
       " array([0.25, 0.  , 0.37, 0.  , 1.  , 0.38, 0.  , 0.  , 1.  , 0.52, 0.87,\n",
       "        0.65, 0.06, 0.06, 1.  , 1.  , 0.  , 0.  , 1.  , 0.13, 1.  , 0.02,\n",
       "        0.02, 1.  , 0.02, 1.  , 1.  , 0.  , 0.  , 0.03, 0.22, 0.13])>,\n",
       " 'dst_host_diff_srv_rate': <tf.Tensor: id=516, shape=(32,), dtype=float64, numpy=\n",
       " array([1.  , 0.62, 0.02, 1.  , 0.  , 0.02, 0.27, 1.  , 0.  , 0.48, 0.01,\n",
       "        0.01, 1.  , 0.94, 0.  , 0.  , 1.  , 0.91, 0.  , 0.02, 0.  , 1.  ,\n",
       "        1.  , 0.  , 1.  , 0.  , 0.  , 0.45, 0.86, 0.06, 0.02, 0.02])>,\n",
       " 'dst_host_same_src_port_rate': <tf.Tensor: id=518, shape=(32,), dtype=float64, numpy=\n",
       " array([0.25, 0.61, 0.37, 0.  , 0.03, 0.38, 0.  , 0.  , 1.  , 0.52, 0.87,\n",
       "        0.65, 0.06, 0.  , 0.  , 0.  , 1.  , 0.  , 0.05, 0.13, 1.  , 0.02,\n",
       "        0.02, 0.  , 0.02, 0.01, 0.  , 0.  , 0.  , 0.  , 0.22, 0.13])>,\n",
       " 'dst_host_srv_diff_host_rate': <tf.Tensor: id=522, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])>,\n",
       " 'dst_host_serror_rate': <tf.Tensor: id=520, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 0.08, 0.  , 0.  , 0.  , 0.08, 0.  , 0.09, 0.  ,\n",
       "        0.  , 0.  , 0.08, 0.  , 0.  , 1.  , 0.08, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.01, 0.  , 0.  , 0.01, 0.  , 0.05, 1.  , 0.  , 0.  ])>,\n",
       " 'dst_host_srv_serror_rate': <tf.Tensor: id=524, shape=(32,), dtype=float64, numpy=\n",
       " array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 1.  , 0.  , 0.  ])>,\n",
       " 'dst_host_rerror_rate': <tf.Tensor: id=517, shape=(32,), dtype=float64, numpy=\n",
       " array([0.75, 0.61, 0.  , 0.91, 0.  , 0.47, 0.23, 0.91, 0.  , 0.39, 0.  ,\n",
       "        0.  , 0.88, 0.92, 0.05, 0.06, 0.  , 0.92, 0.1 , 0.  , 0.  , 0.92,\n",
       "        0.93, 0.02, 0.91, 0.06, 0.04, 0.4 , 0.75, 0.  , 0.  , 0.  ])>,\n",
       " 'dst_host_srv_rerror_rate': <tf.Tensor: id=523, shape=(32,), dtype=float64, numpy=\n",
       " array([1.  , 1.  , 0.  , 1.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 1.  , 1.  , 0.05, 0.06, 0.  , 1.  , 0.1 , 0.  , 0.  , 1.  ,\n",
       "        1.  , 0.02, 1.  , 0.06, 0.04, 1.  , 1.  , 0.  , 0.  , 0.  ])>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = next(iter(dataset))[0]\n",
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "protocol = feature_column.numeric_column('protocol_type')\n",
    "demo(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "protocol_buckets = feature_column.bucketized_column(protocol, boundaries=[0, 1])\n",
    "demo(protocol_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /home/leadness/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/leadness/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "protocol = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'protocol_type', [0, 1, 2])\n",
    "\n",
    "thal_one_hot = feature_column.indicator_column(protocol)\n",
    "demo(thal_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 41], [0, 4, 5, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 22, 31, 32])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attrs, num_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df[1].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teardrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teardrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teardrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teardrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teardrop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0            0              0        0     0       1032          0     0   \n",
       "1            0              0        0     0       1032          0     0   \n",
       "2            0              0        0     0       1032          0     0   \n",
       "3            0              0        0     0       1032          0     0   \n",
       "4            0              0        0     0       1032          0     0   \n",
       "...        ...            ...      ...   ...        ...        ...   ...   \n",
       "6995         0              2        1     0         28          0     0   \n",
       "6996         0              2        1     0         28          0     0   \n",
       "6997         0              2        1     0         28          0     0   \n",
       "6998         0              2        1     0         28          0     0   \n",
       "6999         0              2        1     0         28          0     0   \n",
       "\n",
       "      wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0                  0       0    0  ...                   1   \n",
       "1                  0       0    0  ...                   2   \n",
       "2                  0       0    0  ...                   3   \n",
       "3                  0       0    0  ...                   4   \n",
       "4                  0       0    0  ...                   5   \n",
       "...              ...     ...  ...  ...                 ...   \n",
       "6995               3       0    0  ...                  15   \n",
       "6996               3       0    0  ...                  16   \n",
       "6997               3       0    0  ...                  17   \n",
       "6998               3       0    0  ...                  18   \n",
       "6999               3       0    0  ...                  19   \n",
       "\n",
       "      dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                       0.01                    0.02   \n",
       "1                       0.01                    0.02   \n",
       "2                       0.02                    0.02   \n",
       "3                       0.03                    0.02   \n",
       "4                       0.03                    0.02   \n",
       "...                      ...                     ...   \n",
       "6995                    0.07                    0.71   \n",
       "6996                    0.07                    0.71   \n",
       "6997                    0.07                    0.71   \n",
       "6998                    0.08                    0.71   \n",
       "6999                    0.08                    0.70   \n",
       "\n",
       "      dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                            0.01                          0.0   \n",
       "1                            0.01                          0.0   \n",
       "2                            0.02                          0.0   \n",
       "3                            0.03                          0.0   \n",
       "4                            0.03                          0.0   \n",
       "...                           ...                          ...   \n",
       "6995                         0.07                          0.0   \n",
       "6996                         0.07                          0.0   \n",
       "6997                         0.07                          0.0   \n",
       "6998                         0.08                          0.0   \n",
       "6999                         0.08                          0.0   \n",
       "\n",
       "      dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                     0.00                       0.0                  0.00   \n",
       "1                     0.00                       0.0                  0.00   \n",
       "2                     0.00                       0.0                  0.00   \n",
       "3                     0.00                       0.0                  0.00   \n",
       "4                     0.00                       0.0                  0.00   \n",
       "...                    ...                       ...                   ...   \n",
       "6995                  0.03                       0.0                  0.58   \n",
       "6996                  0.03                       0.0                  0.58   \n",
       "6997                  0.03                       0.0                  0.57   \n",
       "6998                  0.03                       0.0                  0.57   \n",
       "6999                  0.03                       0.0                  0.57   \n",
       "\n",
       "      dst_host_srv_rerror_rate        41  \n",
       "0                          0.0     smurf  \n",
       "1                          0.0     smurf  \n",
       "2                          0.0     smurf  \n",
       "3                          0.0     smurf  \n",
       "4                          0.0     smurf  \n",
       "...                        ...       ...  \n",
       "6995                       0.0  teardrop  \n",
       "6996                       0.0  teardrop  \n",
       "6997                       0.0  teardrop  \n",
       "6998                       0.0  teardrop  \n",
       "6999                       0.0  teardrop  \n",
       "\n",
       "[7000 rows x 42 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.rename(columns={i : new_name for i, new_name in enumerate(features_types_dict)})\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# численные столбцы\n",
    "for header in num_attrs:\n",
    "    feature_columns.append(feature_column.numeric_column(attrs[header]))\n",
    "\n",
    "# столбцы индикаторы\n",
    "for header in cat_attrs[:-1]:\n",
    "    l = list(train_df[attrs[header]].value_counts().keys())\n",
    "    thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "          attrs[header], l)\n",
    "    one_hot = feature_column.indicator_column(thal)\n",
    "    feature_columns.append(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_layer,\n",
    "        #tf.keras.layers.Dense(25, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(3, activation='relu'),\n",
    "        tf.keras.layers.Dense(15, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passing a dictionary input to a Sequential Model which doesn't have FeatureLayer as the first layer is an error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-e20f20305f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mFeatureLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \"\"\"\n\u001b[0;32m-> 2697\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_input_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_input_attrs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;31m# We assert that the first layer is a FeatureLayer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feature_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m           raise ValueError('Passing a dictionary input to a Sequential Model '\n\u001b[0m\u001b[1;32m   2732\u001b[0m                            \u001b[0;34m'which doesn\\'t have FeatureLayer as the first layer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m                            ' is an error.')\n",
      "\u001b[0;31mValueError\u001b[0m: Passing a dictionary input to a Sequential Model which doesn't have FeatureLayer as the first layer is an error."
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "epochs = 10\n",
    "history = model.fit(dataset, validation_data=val_dataset, use_multiprocessing=True, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7324 - accuracy: 0.7830\n",
      "Accuracy on test dataset: 0.783\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Accuracy on test dataset:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
